Rishin's guide to thread synchronisation for memory consistency
===============================================================

Thread synchronization is the concurrent execution of two or more threads that share common resources. The common resource is most often a memory location, but it can also be system resources like file descriptors. Without synchronisation, concurrent access invariably leads to corruption of the resource. In case of memory this corruption is called "memory inconsistency error". This article primarily deals with alternative strategies for synchronisation to have memory consistency and their relative performances.

When we talk about accessing a memory region shared between threads it excludes stack and thread-local variables since these cannot be shared. Only data-segment and heap variables need to be synchronised. In ISO-C standard terms stack and thread-local would have automatic and thread storage duration, while data-segment and heap would have static and allocated storage duratin. See C11 standard (ISO/IEC 9899:2011): Section 6.2.4 for details.

Access to memory means either *read* or *write*, however strategies for synchronisation do not correlate directly to these methods. Mainly four strategies for synchronisation exists:

Read-only synchronisation
: A variable which is read-only cannot lead to memory coherency issues since its state is never modified. A common strategy is to initalise these kind of variables before spawing threads, and then do read-only accesses to them from the threads. An more advanced example would be the usage of the immutability pattern where a variable is initialised once and for any subsequent modification a copy of the variable is created. Due to the straightforward nature of these strategies, these methods will not be covered in detail. TODO link to immmutability https://en.wikipedia.org/wiki/Immutable_object.

Write-only synchronisation
: For this case the variable is blindly modified with little regards to its previous state. Common example where this kind of synchronisation might be necessary would be statistics counters which are constantly incremented or decremented by multiple threads. TODO link to below.

Lock based synchronisation
: For all complex cases where the state of the common memory needs to be checked before modification we need to use a system provided locking mechanism. This also applies to cases where one common memory variable needs to be checked before modifying a different common memory variable. TODO link to below.

Flag based synchronisation
: For special cases we can use a simple primitives for doing boolean valued synchronisation. Due to the irregular nature of this pattern, we will explain them on case-by-case basis. TODO link to below.


Memory consistency for write-only cases
---------------------------------------

Consider a simple case where a variable is incremented and decremented at the same time in two separate threads. We have a static storage duration variable as follows:

!INCLUDECODE "sync_wo.c" (c), 18:18

The naive incrementer and decrementer routines are as follows:

!INCLUDECODE "sync_wo.c" (c), 22:41

We start these two in two separate threads:

!INCLUDECODE "sync_wo.c" (c), 148:190

Note that `THREAD_COUNT` variable is macro with value `2` (any even number for this example should work). From a naive point of view, the `shared_value` should be incremented and decremeted the same number of time (`loop_count` number of times). However this is the output we get from the program:

```
$ gcc -DBUILD_UNSAFE sync_wo.c -lpthread -o tester
$ ./tester 100000
Value before starting: 0
Value after ending: -92109
```

The error we get is completely random, and different runs will provide different values. Note that we need to pass reasonably high parameter for `loop_count` as `100000` to see an error. This is explained in the section below.

To try this example on your own, you can find the complete code at TODO https://github.com/tinkerbeast/blogrepo/blob/master/19w28-syncguide/sync_wo.c.

### Reason for memory inconsistency

To understand the incosistency we need to see the assembly dump of our incrementer and decrementer functions: 

The single expression `shared_value++` in assembly translates to:

```
  400797:	8b 05 c7 08 20 00    	mov    0x2008c7(%rip),%eax
  40079d:	83 c0 01             	add    $0x1,%eax
  4007a0:	89 05 be 08 20 00    	mov    %eax,0x2008be(%rip)
```
And the `shared_value--` translates to:

```
  4007cf:	8b 05 8f 08 20 00    	mov    0x20088f(%rip),%eax        
  4007d5:	83 e8 01             	sub    $0x1,%eax
  4007d8:	89 05 86 08 20 00    	mov    %eax,0x200886(%rip)
```  

In both cases the first `mov` instruction loads the value into register `%eax`. After that the `add` or `sub` instruction either increments or decrements. The second `mov` instrunctions stores it back. So the sequence of operations is:

1. Load value from memory to register
2. Increment / decrement register
3. Store value to memory from register

This three step process is precisely what causes the issue. Two possible scenarios might be their based on single-processor or multi-processor execution.

The first scenario is a single processor based execution with pre-emptive scheduling. Consider the following sequence of events:

* Thread 1 loads value (let's say 100)
* Thread 1 get's preempted due to scheduling (register value is context saved as 100)
* Thread 2 loads value (value is still 100)
* Thread 2 decrements value (register value 99)
* Thread 2 stores value (value stored is 99)
* Thread 1 is scheduled back in (register value is context restored as 100)
* Thread 1 increments the value (register value 101)
* Thread 1 stores back the value (value stored is 101)

Since both thread 1 incremented once, and thread 2 decremented once, the intial value 100 should have been unchanged after execution. However due to the interleaving nature of pre-emption the outcome value became 101.

For the second scenario we have multi processor based execution where two threads run in parallel. So we can interleave the instructions in any way we want, for example:

TODO side by side layout

* Thread 1 loads value (let's say 100)
* Thread 2 loads value (value is still 100)
* Thread 1 increments the value (register value 101)
* Thread 2 decrements value (register value 99)
* Thread 1 stores back the value (value stored is 101)
* Thread 2 stores value (value stored is 99)

Just like the previous case increment and decrement happened once on value 100, but the outcome value was 99. So memory-inconsistency has been demonstrated for both single processor or multi-processor environments.

Note that we previously mentioned that we need to pass a reasonably high parameter for `loop_count` as `100000` to see an error. For the first scenario, thread pre-emption will generally happen once the thread has used up its entire time slot assigned by the operating system. With a small value, the chances of using up its entire time slot decreases. For the second case, the way our programme is written, we start the threads one by one. It just might be the cases that one thread finishes up its execution before the second thread is scheduled in. **NOTE** that this caveat can in no way be exploited for general synchronisation needs since the pre-emption and scheduling are beyond the scope of our control. 









